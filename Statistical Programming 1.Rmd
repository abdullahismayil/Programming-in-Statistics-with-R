---
title: 'Programming in statistics: Assignment 4'
author: 'Abdullah Ismayilzada'
date: "09/10/2023"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instructions
A report with your solutions should be uploaded to Canvas. In addition, upload any .R and/or .Rmd files needed to produce your solutions. The report should be a pdf document. It should be a self-explanatory document, i.e., understandable without having to read the assignment specification. The report should contain the name of the assignment, your name and date, the problems that you are trying to solve as well as the solutions (including **explanatory text**, R-code, tables/figures etc). Include all your R code in the report (in the text or as an appendix) and remember to comment your code.

The aim of this course is for you to enhance your R programming skills, and learning by doing is really the way to get there. That said, you are encouraged to discuss course material with each other. However, the solutions and the report you hand in should be your own work.






## A: A Function
Consider the following semi-parametric additive model:
\begin{equation}\label{m}
y_i = \sum_{j=1}^J f_j(x_{ji}) + \beta z_i + \epsilon_i, \quad i = 1, \dots , n
\end{equation}
It is similar to an ordinary (parametric) multiple regression, but in \eqref{m} the $J$ explanatory variables are modeled by using non-parametric smooth functions, e.g., because they are considered to be nuisance variables, and thus not of main interest. The only variable that enters the model parametrically is, in this case, $z$ and we consider $\beta$ to be the target parameter (the parameter of main interest).


Write a function that compares different estimators of the target parameter $\beta$ in \eqref{m}. 

- **G level**: The first estimator you should implement in your function is the one given by the \texttt{gam} function in the \texttt{mgcv} package. Secondly, you should implement either a LASSO, ridge or elasticnet regression estimator (see \texttt{glmnet} package), where the model "ignores" the smooth functions in \eqref{m}, i.e., it models
\begin{equation}\label{m2}
y_i = \sum_{j=1}^J \tau_j x_{ji} + \beta z_i + \epsilon_i, \quad i = 1, \dots , n.
\end{equation}
And lastly, for comparison you should also include the least square estimate of $\beta$, also assuming model \eqref{m2}.



- **VG level**: In addition to the three estimators implemented on the G level, you should implement a fourth estimator for  $\beta$ in \eqref{m}. This should be the one given by the \texttt{gam} function in the \texttt{gam} package. 
[Hint: Make sure \texttt{R} knows which package you want to use for the \texttt{gam} and \texttt{s} functions, read the section "Packages" in the manual "An Introduction to R" for more help]. 


For both grade levels, your function should take the data, i.e., a response variable ($Y$), the target explanatory variable ($Z$), and the $J$ other explanatory variables, as formal argument(s).
The function should be written in such a way that it can adapt to different numbers of explanatory variables without having to be re-written. [Hint: The functions \texttt{formula} and \texttt{paste} are useful].


The function should return (at minimum) the different estimates $\hat{\beta}_{mgcv}$, $\hat{\beta}_{glmnet}$ and $\hat{\beta}_{ls}$ (and $\hat{\beta}_{gam}$). 

Lastly, test your function by running it on a data frame containing data from the dataset \texttt{ragweed} found in the package \texttt{SemiPar}. Consider \verb#ragweed$ragweed# the response variable, 
\verb#ragweed$rain# the target variable ($Z$), and 
\verb#ragweed$temperature#, 
\verb#ragweed$wind.speed#, and
\verb#ragweed$day.in.seas# the three covariates of interest.

# Load necessary packages
library(mgcv)  # for gam function from mgcv package
library(glmnet)  # for LASSO, ridge, elasticnet regression
library(gam)  # for gam function from gam package

# Define the function to compare estimators
compare_estimators <- function(data, response_var, target_var, covariates_of_interest, method = c("gam", "lasso", "ridge", "elasticnet")) {
  # Extract the response variable
  y <- data[[response_var]]
  
  # Extract the target variable
  z <- data[[target_var]]
  
  # Extract the covariates of interest
  covariates <- data[, covariates_of_interest]
  
  # Initialize a list to store the results
  results <- list()
  
  
for (m in method) {
  if (m == "gam") {
    # Fit the GAM model using mgcv package's gam function
    gam_formula <- as.formula(paste(response_var, "~ s(", paste(covariates_of_interest, collapse = " + "), ") + ", target_var))
    gam_model <- gam(gam_formula, data = data)
    beta_gam <- coef(gam_model)[target_var]
    results[[paste("beta_", m, sep = "")]] <- beta_gam
  } else if (m %in% c("lasso", "ridge", "elasticnet")) {
    # Prepare the design matrix
    X <- model.matrix(as.formula(paste(response_var, "~", paste(covariates_of_interest, collapse = " + "), "+", target_var)), data = data)
    # Fit the glmnet model
    glmnet_model <- glmnet::glmnet(X, y, alpha = ifelse(m == "lasso", 1, 0.5))
    beta_reg <- coef(glmnet_model)[, 1]  # Extract the first beta value
    results[[paste("beta_", m, sep = "")]] <- beta_reg
  } else if (m == "vg") {
    # Fit the GAM model using gam function from gam package
    gam_formula_vg <- as.formula(paste(response_var, "~ s(", paste(covariates_of_interest, collapse = " + "), ") + ", target_var))
    gam_model_vg <- gam(gam_formula_vg, data = data)
    beta_gam_vg <- coef(gam_model_vg)[target_var]
    results[[paste("beta_", m, "_vg", sep = "")]] <- beta_gam_vg
  } else {
    stop(paste("Invalid method:", m, ". Choose 'gam', 'lasso', 'ridge', 'elasticnet', or 'vg'."))
  }
}



  
  # Fit least squares model assuming model m2
  lm_formula <- as.formula(paste(response_var, "~", paste(covariates_of_interest, collapse = " + "), "+", target_var))
  lm_model <- lm(lm_formula, data = data)
  beta_ls <- coef(lm_model)[target_var]
  results[["beta_least_squares"]] <- beta_ls
  
  return(results)
}

# Load necessary packages
library(SemiPar)

# Load the ragweed dataset
data(ragweed)


# Define the variables as described in the task
response_var <- "ragweed"
target_var <- "rain"
covariates_of_interest <- c("temperature", "wind.speed", "day.in.seas")

# Call your compare_estimators function
estimates <- compare_estimators(ragweed, response_var, target_var, covariates_of_interest, method = c("gam", "lasso", "ridge", "elasticnet"))

# Access the estimated betas for each method
beta_gam <- estimates$beta_gam
beta_lasso <- estimates$beta_lasso
beta_ridge <- estimates$beta_ridge
beta_elasticnet <- estimates$beta_elasticnet
beta_least_squares <- estimates$beta_least_squares


## B: Vectorization
Consider the following representation of the second Bernoulli numbers
\begin{equation}
B_n = \sum_{k=0}^n \frac{1}{k+1} \sum_{j=0}^k (-1)^j (j+1)^n \binom{k}{j} 
= \sum_{k=0}^n  \sum_{j=0}^k \frac{1}{k+1} (-1)^j (j+1)^n \binom{k}{j}.
\end{equation}
The $\binom{k}{j}$ term can be calculated using the `choose` function in R.

- **G level**: 1) Write a function that calculates $B_n$ using two loops (one for each summation). 2) Write another (more efficient) function that calculates $B_n$ by using a single loop (for the outer summation only).

- **VG level**: In addition to the functions in G level, try to write a third function that calculates $B_n$ without using any loops (nor the `apply` family of functions), i.e., all summation in vectorized computation.

Test your functions by calculating $B_4$ and $B_{10}$. When you are finished use \texttt{microbenchmark} to evaluate your functions' efficiency.


# Function to calculate Bn using two loops
calculate_Bernoulli_two_loops <- function(n) {
  Bn <- 0
  for (k in 0:n) {
    inner_sum <- 0
    for (j in 0:k) {
      inner_sum <- inner_sum + ((-1)^j) * choose(k, j) * (j + 1)^n
    }
    Bn <- Bn + inner_sum / (k + 1)
  }
  return(Bn)
}

# Function to calculate Bn using a single loop
calculate_Bernoulli_single_loop <- function(n) {
  Bn <- 0
  for (k in 0:n) {
    j <- 0:k
    term <- sum((-1)^j * choose(k, j) * (j + 1)^n)
    Bn <- Bn + term / (k + 1)
  }
  return(Bn)
}





# Function to calculate Bn using vectorized computation
calculate_Bernoulli_vectorized <- function(n) {
  k <- 0:n
  j <- matrix(0:max(k), ncol = length(k), byrow = TRUE)
  Bn <- sum((-1)^j * choose(k, j) * (j + 1)^n / (k + 1))
  return(Bn)
}



# Load the microbenchmark library
library(microbenchmark)

# Calculate B4 and B10 using all three functions
B4_two_loops <- calculate_Bernoulli_two_loops(4)
B4_single_loop <- calculate_Bernoulli_single_loop(4)
B4_vectorized <- calculate_Bernoulli_vectorized(4)

B10_two_loops <- calculate_Bernoulli_two_loops(10)
B10_single_loop <- calculate_Bernoulli_single_loop(10)
B10_vectorized <- calculate_Bernoulli_vectorized(10)

# Print the results for B4 and B10
cat("B4 (Two Loops):", B4_two_loops, "\n")
cat("B4 (Single Loop):", B4_single_loop, "\n")
cat("B4 (Vectorized):", B4_vectorized, "\n")

cat("B10 (Two Loops):", B10_two_loops, "\n")
cat("B10 (Single Loop):", B10_single_loop, "\n")
cat("B10 (Vectorized):", B10_vectorized, "\n")

# Benchmark the functions
benchmark_result <- microbenchmark(
  "Two Loops (B4)" = calculate_Bernoulli_two_loops(4),
  "Single Loop (B4)" = calculate_Bernoulli_single_loop(4),
  "Vectorized (B4)" = calculate_Bernoulli_vectorized(4),
  "Two Loops (B10)" = calculate_Bernoulli_two_loops(10),
  "Single Loop (B10)" = calculate_Bernoulli_single_loop(10),
  "Vectorized (B10)" = calculate_Bernoulli_vectorized(10),
  times = 10000  # Adjust the number of repetitions as needed
)

# Print the benchmark results
print(benchmark_result)




## C: Graphics

Load the `CO2` dataset which is available in `R` and write code to reproduce Figure 1 (shown below) as closely as you can, including the same axes, labels, legend, header etc. You may use which ever functions/packages you like.

Hints:

- You can learn about the data by looking at the helpfile: `?CO2`
- You can load data by `data(CO2)`.
- The following functions might be useful: `aggregate`, `layout`, `plot`, `par`, `lines`, `expression`, `legend`, `axis`, `mtext`, `density`. Try to read their help documents.

Note! Your figure does not need to have the exact same scaling, lines or color choices. You may experiment and choose what you think is best!



#Load the data
data(CO2)

# Set up a multi-panel layout with 3 rows and 1 column
par(mfrow = c(3, 1))

# Plot 1: Mean CO2 uptake curves for four categories
plot(uptake ~ conc, data = CO2, type = "n", xlab = "Ambient CO2 concentration (mL/L)",
     ylab = "Mean CO2 uptake rates (mmol/m^2 sec)", main = "Mean CO2 Uptake Curves",
     xlim = c(0, 1100), ylim = c(0, 50), xaxt = "n", yaxt = "n")

# Calculate the mean CO2 uptake rates for each category
quebec_nonchilled_mean <- aggregate(uptake ~ conc, data = CO2[CO2$Type == "Quebec" & CO2$Treatment == "nonchilled", ], mean)
quebec_chilled_mean <- aggregate(uptake ~ conc, data = CO2[CO2$Type == "Quebec" & CO2$Treatment == "chilled", ], mean)
mississippi_nonchilled_mean <- aggregate(uptake ~ conc, data = CO2[CO2$Type == "Mississippi" & CO2$Treatment == "nonchilled", ], mean)
mississippi_chilled_mean <- aggregate(uptake ~ conc, data = CO2[CO2$Type == "Mississippi" & CO2$Treatment == "chilled", ], mean)

# Plot lines for the mean values of the four categories
lines(quebec_nonchilled_mean$conc, quebec_nonchilled_mean$uptake, col = "red", type = "b", pch = 19)
lines(quebec_chilled_mean$conc, quebec_chilled_mean$uptake, col = "blue", type = "b", pch = 2)
lines(mississippi_nonchilled_mean$conc, mississippi_nonchilled_mean$uptake, col = "brown", type = "b", pch = 3)
lines(mississippi_chilled_mean$conc, mississippi_chilled_mean$uptake, col = "darkblue", type = "b", pch = 4)

# Add custom axis labels and tick marks
axis(side = 2, at = seq(0, 50, 10), labels = seq(0, 50, 10))
axis(side = 1, at = c(95, 175, 250, 350, 500, 675, 1000),
     labels = c(95, 175, 250, 350, 500, 675, 1000))

# Add legend
legend("bottomright", legend = c("Quebec Nonchilled", "Quebec Chilled",
                              "Mississippi Nonchilled", "Mississippi Chilled"),
       col = c("red", "blue", "brown", "darkblue"), pch = c(19, 2, 3, 4), title = "Lines", cex=0.8)



# Plot 2: Boxplot for CO2 uptake in terms of plant origin
par(mar = c(4, 4, 2, 2))

# Create a grouping variable for the boxplot
CO2$Plant_Origin <- ifelse(grepl("Quebec", CO2$Type), "Quebec", "Mississippi")

# Define custom colors
colors <- c("cyan", "green")

# Create the boxplot
boxplot(uptake ~ Plant_Origin, data = CO2, xlab = "Plant Origin",
        ylab = "CO2 uptake rates (mmol/m^2 sec)", col = colors, names = c("Quebec", "Mississippi"))

# Add custom axis labels for y-axis and tick marks
axis(side = 2, at = seq(10, 40, 10), labels = seq(10, 40, 10))

# Add a title for the second plot
title("Boxplot for CO2 Uptake in Terms of Plant Origin")


# Plot 3: Histogram of CO2 uptake rates
par(mar = c(4, 4, 2, 2))

# Create histogram data
hist_data <- hist(CO2$uptake, plot = FALSE)

# Create a histogram with dashed lines
plot(hist_data, xlab = "", ylab = "Density",
     main = "Histogram of CO2 Uptake Rates", freq = FALSE, col = "white")

# Add a density plot with dashed lines
lines(density(CO2$uptake), col = "orange", lty = 2, lwd=5)

# Add custom axis labels for y-axis and tick marks
axis(side = 2, at = c(0.000, 0.010, 0.020, 0.030), labels = c(0.000, 0.010, 0.020, 0.030))
axis(side = 1, at = c(10, 20, 30, 40, 50), labels = c(10, 20, 30, 40, 50))

# Reset the layout to the default (1 plot per page)
par(mfrow = c(1, 1))













